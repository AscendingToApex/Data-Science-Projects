{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colorado Elk Tag Application Data Collection\n",
    "\n",
    "Raw Data that was ingested can be found [Here](https://cpw.state.co.us/thingstodo/Pages/Statistics-Elk.aspx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import pdfplumber\n",
    "import os\n",
    "import shutil\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "1    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "2    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "3    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "4    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "5    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "6    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "7    https://cpw.state.co.us/Documents/Hunting/BigG...\n",
      "Name: URL, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Webscraping URL's Related to Elk Draw Recaps\n",
    "#Scraping html\n",
    "url = 'https://cpw.state.co.us/thingstodo/Pages/Statistics-Elk.aspx'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "#isolating href files to a list\n",
    "site_URLs = []\n",
    "for link in soup.find_all('a'):\n",
    "    site_URLs.append((link.get('href')))\n",
    "\n",
    "#Converting to DataFrame and Filtering for information on Draw Recap Statistics\n",
    "elk_URL_DF_Raw = pd.DataFrame(site_URLs,columns =['URL'])\n",
    "elk_URL_DF_Filtered = elk_URL_DF_Raw.loc[elk_URL_DF_Raw['URL'].str.contains('/Documents/Hunting/BigGame/Statistics/ELK',case=False,na=False)]\n",
    "elk_URL_DF_Filtered = elk_URL_DF_Filtered.loc[elk_URL_DF_Raw['URL'].str.contains('ElkDrawRecap.pdf',case=False,na=False)]\n",
    "elk_URL_DF_Filtered['URL'] = 'https://cpw.state.co.us' + elk_URL_DF_Filtered['URL'].astype(str)\n",
    "elk_URL_DF_Filtered.reset_index(inplace = True, drop=True)\n",
    "\n",
    "print(elk_URL_DF_Filtered['URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "\n",
    "    with requests.get(url) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "    return local_filename\n",
    "\n",
    "def check_space(string):\n",
    "    \"\"\"Function that returns the number of strings of the inputted string\"\"\"\n",
    "    count = 0\n",
    "    for i in string:\n",
    "        if i == \" \":\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def find_hunt_code(df):\n",
    "    \"\"\"\n",
    "    Input: Dataframe from the pdf page\n",
    "\n",
    "    Output: Huntcode as a string\n",
    "    \"\"\"\n",
    "    # Utilize a regular expression to find the Hunt Code\n",
    "    Hunt_Code_Search = search('[A-Z]{2}\\d{3}[A-Z]{1}\\d{1}[A-Z]{1}',df.iloc[2,0])\n",
    "\n",
    "    try:\n",
    "        Hunt_Code = Hunt_Code_Search.group(0)\n",
    "        Hunt_Code_Storage = Hunt_Code_Search.group(0)\n",
    "    except:\n",
    "        Hunt_Code = None\n",
    "    \n",
    "    return Hunt_Code\n",
    "\n",
    "def strip_whitespace(df):\n",
    "    \"\"\"\n",
    "    Input: Dataframe from the pdf page\n",
    "    \n",
    "    Output: Dataframe with whitespaces stripped\n",
    "    \"\"\"\n",
    "    # Verifying that the dtypes are objects\n",
    "    df_object = df.select_dtypes(['object'])\n",
    "\n",
    "    #Strip all white spaces\n",
    "    df[df_object.columns] = df_object.apply(lambda x: x.str.strip())\n",
    "\n",
    "    return df\n",
    "\n",
    "def find_preference_point_table(df):\n",
    "    \"\"\"\n",
    "    Input: Dataframe from the pdf page\n",
    "\n",
    "    Output: Preference Point table or Null\n",
    "    \"\"\"\n",
    "    try:\n",
    "        PP_Start = df.loc[df['                  Colorado Parks and Wildlife   Draw Recap'].str.contains('Choice Preference',na=False,case=False)]\n",
    "        Preference_Points = df.iloc[PP_Start.index[0]+1:]\n",
    "    except:\n",
    "        PP_Start = df.loc[df['                  Colorado Parks and Wildlife   Draw Recap'].str.contains('Page',na=False,case=False)]\n",
    "        Preference_Points = df.iloc[PP_Start.index[0]+1:]\n",
    "    \n",
    "    return Preference_Points\n",
    "\n",
    "def choice_finder(df):\n",
    "    \"\"\"\n",
    "    Input: Pre processing Preference Points Dataframe\n",
    "    \n",
    "    Output: Isolated Column\n",
    "    \"\"\"\n",
    "    #Check how many spaces are in the strings to see if its in the standardized format, or if an extra character is there\n",
    "    df['Choice Finder'] = df[\"Preference Points Table Buffer\"].apply(lambda x: check_space(x))\n",
    "\n",
    "    #Check if the number of spaces matches the number in the standardized format and the format with the choice included\n",
    "    df = df.loc[(df['Choice Finder'] == 15) | (df['Choice Finder'] == 13)]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    #Isolate the choice made in the draw, which is indicated based on a string length of 15\n",
    "    df['Choice'] = [x[:1] if y == 15 else None for x,y in zip(df['Preference Points Table Buffer'],df['Choice Finder']) ]\n",
    "    Choice_Index = df[df['Choice'].notnull()].index\n",
    "    df.bfill(axis='rows',inplace=True)\n",
    "    df.ffill(axis='rows',inplace=True)\n",
    "\n",
    "    #Table to merge choices by index after the preference points transpormation is complete\n",
    "    Choice_Merge = df['Choice']\n",
    "\n",
    "    #Restucting rows that had the choice in with the preference points values\n",
    "    df['Preference Points Table Buffer'] = [x[2:] if y == 15 else x for x,y in zip(df['Preference Points Table Buffer'],df['Choice Finder'])]\n",
    "\n",
    "    return df, Choice_Merge, Choice_Index\n",
    "\n",
    "def preference_points_clean_up(df,Choice_Index):\n",
    "    \"\"\"\n",
    "    Input: Preference Points Buffer 2 and the Choice Index\n",
    "        \n",
    "    Output: Cleaned up preference points table\n",
    "    \"\"\"\n",
    "\n",
    "    #Expand the restructured preference point dataframe, so it matches the format in the pdf\n",
    "    df_Expanded = df.iloc[:,0].str.split(' ',expand=True)\n",
    "\n",
    "    try:\n",
    "        df_Expanded = df_Expanded[[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]]\n",
    "\n",
    "        #For loop to handle the choice being in the draw portion of the preference point table\n",
    "        for j in range(7,14):\n",
    "            df_Expanded.iloc[Choice_Index,j] = df_Expanded.iloc[Choice_Index,j+1]\n",
    "\n",
    "        #Removes the blank column at the end\n",
    "        del df_Expanded[14]\n",
    "\n",
    "        #Remove the redundent preference point column\n",
    "        del df_Expanded[7]\n",
    "\n",
    "    except:\n",
    "        df_Expanded = df_Expanded[[0,1,2,3,4,5,6,7,8,9,10,11,12,13]]\n",
    "\n",
    "        #Remove the redundent preference point column\n",
    "        del df_Expanded[7]\n",
    "\n",
    "    # Remove any residule components that aren't an integer in the preference points columns\n",
    "    df_Expanded[0] = pd.to_numeric(df_Expanded[0],errors = 'coerce')\n",
    "    df_Expanded.dropna(inplace = True)\n",
    "    df_Expanded[0] = pd.to_numeric(df_Expanded[0],downcast=\"integer\")\n",
    "\n",
    "    #Rename the columns, so they correlate with the pdf format\n",
    "    df_Expanded.columns = ['Preference Points','A-Adult-Res','A-Adult-NonRes','A-Youth-Res','A-Youth-NonRes','A-Landowner(LPP)-Unrestricted' \\\n",
    "    ,'A-Landownder(LPP)-Restricted','D-Adult-Res','D-Adult-NonRes','D-Youth-Res','D-Youth-NonRes'\n",
    "    ,'D-Landowner(LPP)-Unrestricted','D-Landownder(LPP)-Restricted']\n",
    "\n",
    "    return df_Expanded\n",
    "\n",
    "def preference_points_finalize(df, Choice_Merge, Hunt_Code, Draw_Year):\n",
    "    \"\"\"\n",
    "    Input: Preference Points Expanded DataFrame, Choice Merge Dataframe, Hunt_Code, and Draw Year\n",
    "\n",
    "    Output: Applicants and Drew Dataframes accordingly\n",
    "    \"\"\"\n",
    "    #Isolate the columns appliable to the draw applicants\n",
    "    Applicant_Preference_Points_Buffer = df[['Preference Points','A-Adult-Res','A-Adult-NonRes','A-Youth-Res','A-Youth-NonRes','A-Landowner(LPP)-Unrestricted' \\\n",
    "    ,'A-Landownder(LPP)-Restricted']]\n",
    "\n",
    "    #Merge the Choice on index; creating the applicant and successful draw dataframe\n",
    "    Applicant_Preference_Points = Applicant_Preference_Points_Buffer.merge(Choice_Merge, left_index=True, right_index=True)\n",
    "\n",
    "    Draw_Preference_Points_Buffer = df[['Preference Points','D-Adult-Res','D-Adult-NonRes','D-Youth-Res','D-Youth-NonRes'\n",
    "    ,'D-Landowner(LPP)-Unrestricted','D-Landownder(LPP)-Restricted']]\n",
    "\n",
    "    Draw_Preference_Points = Draw_Preference_Points_Buffer.merge(Choice_Merge, left_index=True,right_index=True)\n",
    "\n",
    "    #Add the Hunt Code and Draw year to the dataframes\n",
    "    Applicant_Preference_Points['Hunt Code'] = Hunt_Code\n",
    "    Applicant_Preference_Points['Year'] = Draw_Year\n",
    "    Draw_Preference_Points['Hunt Code'] = Hunt_Code\n",
    "    Draw_Preference_Points['Year'] = Draw_Year\n",
    "\n",
    "    #Create a Primary Key for the dataframe\n",
    "    Applicant_Preference_Points['Hunt Key'] = [x + '-' + y + '-' + str(z) for x,y,z in zip(Applicant_Preference_Points['Hunt Code'], \\\n",
    "        Applicant_Preference_Points['Year'],Applicant_Preference_Points['Preference Points'])]\n",
    "    Draw_Preference_Points['Hunt Key'] = [x + '-' + y + '-' + str(z) for x,y,z in zip(Draw_Preference_Points['Hunt Code'],Draw_Preference_Points['Year'] \\\n",
    "        ,Draw_Preference_Points['Preference Points'])]\n",
    "\n",
    "    return Applicant_Preference_Points, Draw_Preference_Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(elk_URL_DF_Filtered)):\n",
    "\n",
    "    stats_url = download_file(elk_URL_DF_Filtered['URL'][i])\n",
    "\n",
    "    # Instanciate empty dataframes for the consolidated output of processed pages\n",
    "    All_Applicant_Preference_Points = pd.DataFrame()\n",
    "    All_Draw_Preference_Points = pd.DataFrame()\n",
    "    Pages_with_issues = []\n",
    "\n",
    "    with pdfplumber.open(stats_url) as pdf:\n",
    "        number_of_pages = len(pdf.pages)\n",
    "        for j in range(2,number_of_pages):\n",
    "            # Export the pdf page's raw text as a dataframe\n",
    "            page = pdf.pages[j]\n",
    "            text = page.extract_text()\n",
    "            df = pd.read_csv(StringIO(text))\n",
    "\n",
    "            #Length of less than 8 skips pages that only have the portions of the summary table below the preference point table\n",
    "            if len(df) > 8:\n",
    "                try:\n",
    "                    #Find the Hunt Code on the page and leave it the same if there isn't one on the page\n",
    "                    Hunt_Code_Buffer = find_hunt_code(df)\n",
    "                    Hunt_Code = Hunt_Code if Hunt_Code_Buffer is None else Hunt_Code_Buffer\n",
    "\n",
    "                    #print('Hunt Code Found Successfully...')\n",
    "\n",
    "                    # Utilize a regular expression to find the Year of the Draw Recap\n",
    "                    Draw_Year_Search = search('\\d{4}',df.iloc[0,0])\n",
    "                    Draw_Year = Draw_Year_Search.group(0)\n",
    "\n",
    "                    #print('Year Found Successfully...')\n",
    "\n",
    "                    #Strip whitespaces\n",
    "                    df_stripped = strip_whitespace(df)\n",
    "\n",
    "                    #print('Whitespaces Stripped Successfully..')\n",
    "\n",
    "                    #Isolating where the preference points portion of the dataframe starts\n",
    "                    Preference_Points_Buffer = find_preference_point_table(df_stripped)\n",
    "\n",
    "                    #print('Preference Point Table Found Successfully...')\n",
    "\n",
    "                    Preference_Points_Buffer.reset_index(inplace=True, drop=True)\n",
    "                    Preference_Points_Buffer.columns = [\"Preference Points Table Buffer\"]\n",
    "\n",
    "                    #print('Index reset and column renamed successfully...')\n",
    "\n",
    "                    #!!!!!!NEED TO LOOK AT UNITS THAT HAVE MULTIPLE CHOICES!!!!!!\n",
    "                    #Isolate the Choice and reformat to a standardize format for separating the preference points\n",
    "                    Preference_Points_Buffer2, Choice_Merge, Choice_Index = choice_finder(Preference_Points_Buffer)\n",
    "\n",
    "                    #print('Choice found successfully...')\n",
    "\n",
    "                    # Reformat Preference Point DataFrame, so it's easier to interpret\n",
    "                    Preference_Points_Expanded = preference_points_clean_up(Preference_Points_Buffer2, Choice_Index)\n",
    "\n",
    "                    #print('Preference Point table cleaned up successfully...')\n",
    "\n",
    "                    #Perform final clean-up to and segregation\n",
    "                    Applicant_Preference_Points, Draw_Preference_Points = preference_points_finalize(Preference_Points_Expanded, Choice_Merge, Hunt_Code, Draw_Year)\n",
    "\n",
    "                    #print('Preference Point Clean-up Completed Successfully')\n",
    "\n",
    "                    #Append to a generalized Dataframe for multiple pages processed\n",
    "                    All_Applicant_Preference_Points = All_Applicant_Preference_Points.append(Applicant_Preference_Points)\n",
    "                    All_Draw_Preference_Points = All_Draw_Preference_Points.append(Draw_Preference_Points)\n",
    "\n",
    "                    #print('Appended to consolidated dataframe successfully')\n",
    "                except:\n",
    "                    Pages_with_issues.append(j)\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    All_Applicant_Preference_Points.to_excel('Output-Data\\\\Applicant-Data\\\\'+ Draw_Year+'-All-Applicant-Preference-Points.xlsx')\n",
    "    All_Draw_Preference_Points.to_excel('Output-Data\\\\Draw-Data\\\\'+Draw_Year+'-All-Draw-Preference-Points.xlsx')\n",
    "    \n",
    "    Pages_With_Issues_DF = pd.DataFrame(Pages_with_issues, columns=['Pages'])\n",
    "    if len(Pages_With_Issues_DF) > 0:\n",
    "        Pages_With_Issues_DF.to_excel('Output-Data\\\\Pages-with-Issues\\\\'+ Draw_Year+'-Pages-With-Issues.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current directory\n",
    "directory = os.getcwd()\n",
    "    \n",
    "#Iterate over the directory looking for the downloaded input pdf documents and put into a separate directory\n",
    "for file in os.listdir(directory):\n",
    "     filename = os.fsdecode(file)\n",
    "     if filename.endswith(\".pdf\"): \n",
    "        original = filename\n",
    "        target = 'Input-Data\\\\'+filename\n",
    "\n",
    "        shutil.move(original, target)\n",
    "        continue\n",
    "     else:\n",
    "         continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92eeafcbabfc37afade1f0f453883f240313697269fbef933ea65d1be2634430"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
