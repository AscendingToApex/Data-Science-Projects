{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "Name: is_arrested, dtype: object\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "Name: is_arrested, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['state', 'stop_date', 'stop_time', 'driver_gender', 'driver_race',\n",
       "       'violation_raw', 'violation', 'search_conducted', 'search_type',\n",
       "       'stop_outcome', 'is_arrested', 'stop_duration', 'drugs_related_stop',\n",
       "       'district'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Traffic stops in Rhode Island\n",
    "ri = pd.read_csv('https://assets.datacamp.com/production/repositories/1497/datasets/62bd9feef451860db02d26553613a299721882e8/police.csv')\n",
    "\n",
    "#Locating missing values and compare to shape of df\n",
    "ri.isnull().sum()\n",
    "ri.shape\n",
    "\n",
    "#Dropping a column since there's no values\n",
    "ri.drop('county_name', axis = 'columns', inplace=True)\n",
    "\n",
    "#Dropping rows with no stop date or stop time\n",
    "ri.dropna(subset=['stop_date','stop_time'],inplace=True)\n",
    "\n",
    "#Checking and fixing data types\n",
    "ri.dtypes\n",
    "\n",
    "# Examine the head of the 'is_arrested' column\n",
    "print(ri.is_arrested.head())\n",
    "\n",
    "# Change the data type of 'is_arrested' to 'bool'\n",
    "ri['is_arrested'] = ri.is_arrested.astype('bool')\n",
    "\n",
    "# Check the data type of 'is_arrested' \n",
    "print(ri.is_arrested.head())\n",
    "\n",
    "#Creating a DatetimeIndex\n",
    "#Combining Stop_date and Stop_time (Object columns)\n",
    "combined = ri.stop_date.str.cat(ri.stop_time, sep=' ')\n",
    "ri['stop_datetime'] = pd.to_datetime(combined)\n",
    "ri.set_index('stop_datetime', inplace=True)\n",
    "ri.index #Verifying Index\n",
    "ri.columns #Verify Columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the relationship between gender and policing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'drive_race'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14684/2717143512.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_outcome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Filtering DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mwhite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mri\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrive_race\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mblack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mri\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrive_race\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'black'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mhispanic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mri\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrive_race\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'hispanic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'drive_race'"
     ]
    }
   ],
   "source": [
    "#Do races commit different violations\n",
    "ri.stop_outcome.value_counts(normalize=True)\n",
    "#Filtering DataFrame rows\n",
    "white = ri[ri.drive_race =='white']\n",
    "black = ri[ri.drive_race =='black']\n",
    "hispanic = ri[ri.drive_race =='hispanic']\n",
    "asian = ri[ri.drive_race =='asian']\n",
    "#Comparing stop outcomes\n",
    "white.stop_outcome.value_counts(normalize=True)\n",
    "black.stop_outcome.value_counts(normalize=True)\n",
    "hispanic.stop_outcome.value_counts(normalize=True)\n",
    "asian.stop_outcome.value_counts(normalize=True)\n",
    "\n",
    "#Do genders commit different violations\n",
    "female = ri[ri.driver_gender == 'F']\n",
    "male = ri[ri.driver_gender == 'M']\n",
    "female.violation.value_counts(normalize=True)\n",
    "male.violation.value_counts(normalize=True)\n",
    "\n",
    "#Does gender affect who gets a ticket for speeding?\n",
    "female_and_speeding = ri[(ri.driver_gender =='F') & (ri.stop_outcome =='Speeding')]\n",
    "male_and_speeding = ri[(ri.driver_gender =='M') & (ri.stop_outcome =='Speeding')]\n",
    "# Compute the stop outcomes for drivers (as proportions)\n",
    "print(female_and_speeding.stop_outcome.value_counts(normalize=True))\n",
    "print(male_and_speeding.stop_outcome.value_counts(normalize=True))\n",
    "\n",
    "#Does gender affect whose vehicle is searched?\n",
    "# Calculate the search rate for drivers\n",
    "print(ri[(ri.driver_gender=='F')].search_conducted.mean())\n",
    "print(ri[(ri.driver_gender=='M')].search_conducted.mean())\n",
    "# Calculate the search rate for both groups simultaneously\n",
    "print(ri.groupby(ri.driver_gender).search_conducted.mean())\n",
    "# Calculate the search rate for each combination of gender and violation\n",
    "print(ri.groupby(['driver_gender', 'violation']).search_conducted.mean())\n",
    "\n",
    "#Does gender affect who is frisked during a search\n",
    "# Count the 'search_type' values\n",
    "print(ri.search_type.value_counts())\n",
    "# Check if 'search_type' contains the string 'Protective Frisk'\n",
    "ri['frisk'] = ri.search_type.str.contains('Protective Frisk', na=False)\n",
    "# Check the data type of 'frisk'\n",
    "print(ri.frisk.dtype)\n",
    "# Take the sum of 'frisk'\n",
    "print(ri.frisk.sum())\n",
    "# Create a DataFrame of stops in which a search was conducted\n",
    "searched = ri[ri.search_conducted == True]\n",
    "# Calculate the overall frisk rate by taking the mean of 'frisk'\n",
    "print(searched.frisk.mean())\n",
    "# Calculate the frisk rate for each gender\n",
    "print(searched.groupby('driver_gender').frisk.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Does time of day affect arrest rate? (Single Variable over time)\n",
    "# Calculate the overall arrest rate\n",
    "print(ri.is_arrested.mean())\n",
    "# Calculate the hourly arrest rate\n",
    "print(ri.groupby(ri.index.hour).is_arrested.mean())\n",
    "# Save the hourly arrest rate\n",
    "hourly_arrest_rate = ri.groupby(ri.index.hour).is_arrested.mean()\n",
    "# Create a line plot of 'hourly_arrest_rate'\n",
    "hourly_arrest_rate.plot()\n",
    "# Add the xlabel, ylabel, and title\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Arrest Rate')\n",
    "plt.title('Arrest Rate by Time of Day')\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "#Are drug-related stops on the rise? (Subplots for 2 variables over time)\n",
    "#Change frequency of timeseries samples with resampling\n",
    "# Calculate and save the annual rate of drug-related stops\n",
    "annual_drug_rate = ri.drugs_related_stop.resample('A').mean()\n",
    "# Calculate and save the annual search rate\n",
    "annual_search_rate = ri.search_conducted.resample('A').mean()\n",
    "# Concatenate 'annual_drug_rate' and 'annual_search_rate'\n",
    "annual = pd.concat([annual_drug_rate, annual_search_rate], axis='columns')\n",
    "# Create subplots from 'annual'\n",
    "annual.plot(subplots=True)\n",
    "# Display the subplots\n",
    "plt.show()\n",
    "\n",
    "#  What violations are caught in each district?\n",
    "# Utilize frequency table with crosstab\n",
    "# Frequency Table: Tally of how many times each combination of values occurs\n",
    "# Create a frequency table of districts and violations\n",
    "# Save the frequency table as 'all_zones'\n",
    "all_zones = pd.crosstab(ri.district, ri.violation)\n",
    "# Save the smaller table as 'k_zones'\n",
    "k_zones = all_zones.loc['Zone K1':'Zone K3']\n",
    "# Create a bar plot of 'k_zones'\n",
    "k_zones.plot(kind='bar')\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#How often searches were done after each violation type?\n",
    "search_rate = ri.groupby('violation').search_conducted.mean()\n",
    "search_rate.sort_values().plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "#How long might you be stopped for a violation?\n",
    "#Translate strings into data to be evaluated numerically\n",
    "# Create a dictionary that maps strings to integers\n",
    "mapping = {'0-15 Min':8,'16-30 Min':23,'30+ Min':45}\n",
    "# Convert the 'stop_duration' strings to integers using the 'mapping'\n",
    "ri['stop_minutes'] = ri.stop_duration.map(mapping)\n",
    "# Print the unique values in 'stop_minutes'\n",
    "print(ri.stop_minutes.unique())\n",
    "# Calculate the mean 'stop_minutes' for each value in 'violation_raw'\n",
    "print(ri.groupby('violation_raw').stop_minutes.mean())\n",
    "# Save the resulting Series as 'stop_length'\n",
    "stop_length = ri.groupby('violation_raw').stop_minutes.mean()\n",
    "# Sort 'stop_length' by its values and create a horizontal bar plot\n",
    "stop_length.sort_values().plot(kind='barh')\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the effect of weather on policing\n",
    "Data from NOAA National Centers for Environmental Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'weather.csv' into a DataFrame named 'weather'\n",
    "weather = pd.read_csv('https://assets.datacamp.com/production/repositories/1497/datasets/02f3fb2d4416d3f6626e1117688e0386784e8e55/weather.csv')\n",
    "\n",
    "# Describe the temperature columns\n",
    "print(weather[['TMIN','TAVG','TMAX']].describe())\n",
    "# Create a box plot of the temperature columns\n",
    "weather[['TMIN','TAVG','TMAX']].plot(kind='box')\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Create a 'TDIFF' column that represents temperature difference\n",
    "weather['TDIFF'] = weather['TMAX']-weather['TMIN']\n",
    "# Describe the 'TDIFF' column\n",
    "print(weather['TDIFF'].describe())\n",
    "# Create a histogram with 20 bins to visualize 'TDIFF'\n",
    "weather['TDIFF'].plot(kind='hist', bins=20)\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "#Categorizing the weather\n",
    "# Copy 'WT01' through 'WT22' to a new DataFrame\n",
    "WT = weather.loc[:,'WT01':'WT22']\n",
    "# Calculate the sum of each row in 'WT'\n",
    "weather['bad_conditions'] = WT.sum(axis='columns')\n",
    "# Replace missing values in 'bad_conditions' with '0'\n",
    "weather['bad_conditions'] = weather.bad_conditions.fillna(0).astype('int')\n",
    "# Create a histogram to visualize 'bad_conditions'\n",
    "weather['bad_conditions'].plot(kind='hist')\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Count the unique values in 'bad_conditions' and sort the index\n",
    "print(weather.bad_conditions.value_counts().sort_index())\n",
    "# Create a dictionary that maps integers to strings\n",
    "mapping = {0:'good', 1:'bad', 2:'bad', 3:'bad',4:'bad',5:'worse',6:'worse',7:'worse',8:'worse',9:'worse'}\n",
    "# Convert the 'bad_conditions' integers to strings using the 'mapping'\n",
    "weather['rating'] = weather.bad_conditions.map(mapping)\n",
    "# Count the unique values in 'rating'\n",
    "print(weather['rating'].value_counts())\n",
    "\n",
    "#Changing data type from object to category to save memory\n",
    "#Inital check of memeory used\n",
    "weather['rating'].memory_usage(deep=True)\n",
    "# Create a list of weather ratings in logical order\n",
    "cats = ['good','bad', 'worse']\n",
    "# Change the data type of 'rating' to category\n",
    "weather['rating'] = weather.rating.astype('category', ordered=True, categories=cats)\n",
    "# Check memory improvements\n",
    "wether['rating'].memory_usage(deep=True)\n",
    "\n",
    "#Merging Datasets\n",
    "# Reset the index of 'ri'\n",
    "ri.reset_index(inplace=True)\n",
    "# Examine the head of 'ri'\n",
    "print(ri.head())\n",
    "# Create a DataFrame from the 'DATE' and 'rating' columns\n",
    "weather_rating = weather[['DATE','rating']]\n",
    "# Examine the head of 'weather_rating'\n",
    "print(weather_rating.head())\n",
    "# Examine the shape of 'ri'\n",
    "print(ri.shape)\n",
    "# Merge 'ri' and 'weather_rating' using a left join\n",
    "ri_weather = pd.merge(left=ri, right=weather_rating, left_on='stop_date', right_on='DATE', how='inner')\n",
    "# Examine the shape of 'ri_weather'\n",
    "print(ri_weather.shape)\n",
    "# Set 'stop_datetime' as the index of 'ri_weather'\n",
    "ri_weather.set_index('stop_datetime', inplace=True)\n",
    "\n",
    "#Does Weather affect the arrest rate?\n",
    "# Calculate the overall arrest rate\n",
    "print(ri_weather.is_arrested.mean())\n",
    "# Calculate the arrest rate for each 'rating'\n",
    "print(ri_weather.groupby('rating').is_arrested.mean())\n",
    "# Calculate the arrest rate for each 'violation' and 'rating'\n",
    "print(ri_weather.groupby(['violation','rating']).is_arrested.mean())\n",
    "# Save the output of the groupby operation from the last exercise\n",
    "arrest_rate = ri_weather.groupby(['violation', 'rating']).is_arrested.mean()\n",
    "# Print the 'arrest_rate' Series\n",
    "print(arrest_rate)\n",
    "# Print the arrest rate for moving violations in bad weather\n",
    "print(arrest_rate.loc['Moving violation', 'bad'])\n",
    "# Print the arrest rates for speeding violations in all three weather conditions\n",
    "print(arrest_rate.loc['Speeding'])\n",
    "# Unstack the 'arrest_rate' Series into a DataFrame\n",
    "print(arrest_rate.unstack())\n",
    "# Create the same DataFrame using a pivot table\n",
    "print(ri_weather.pivot_table(index='violation', columns='driver_gender', values='is_arrested'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdf1b906e0f48476ce4c55dfcaad31f22f6ec2b69337c94e59841b81048e12ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
